{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Firslty we need to scrap data from Wikipedia using Scrapy"
      ],
      "metadata": {
        "id": "9nLssO9pIWHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapy"
      ],
      "metadata": {
        "id": "8jtUyvgXtEyW",
        "outputId": "ad77c2b0-e8ac-44d3-c1f6-c15bbffb8ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.12.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting Twisted>=21.7.0 (from scrapy)\n",
            "  Downloading twisted-24.11.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (43.0.3)\n",
            "Collecting cssselect>=0.9.1 (from scrapy)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy)\n",
            "  Downloading itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy)\n",
            "  Downloading parsel-1.10.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy)\n",
            "  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m626.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
            "  Downloading Protego-0.4.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy)\n",
            "  Downloading itemadapter-0.11.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2)\n",
            "Collecting tldextract (from scrapy)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (5.3.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.7.1)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy) (1.17.1)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (25.1.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.1)\n",
            "Collecting automat>=24.8.0 (from Twisted>=21.7.0->scrapy)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=21.7.0->scrapy)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=21.7.0->scrapy)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from Twisted>=21.7.0->scrapy)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy) (75.1.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (2.32.3)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (3.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2025.1.31)\n",
            "Downloading Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading itemadapter-0.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.10.0-py2.py3-none-any.whl (17 kB)\n",
            "Downloading Protego-0.4.0-py2.py3-none-any.whl (8.6 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: PyDispatcher, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, incremental, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 automat-24.8.1 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.11.0 itemloaders-1.3.2 jmespath-1.0.1 parsel-1.10.0 protego-0.4.0 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 tldextract-5.1.3 w3lib-2.3.1 zope.interface-7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install scrapy\n",
        "!pip install w3lib\n",
        "\n",
        "# Import required libraries\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "import re\n",
        "\n",
        "# Function to clean text data, removing unwanted characters and numbers inside brackets\n",
        "def clean_text_list(text_list):\n",
        "    \"\"\"\n",
        "    Cleans a list of text by removing unwanted characters, numbers in brackets, and extra spaces.\n",
        "\n",
        "    Args:\n",
        "        text_list (list): A list of strings that need to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: A comma-separated string of cleaned text. If the list is empty, returns \"N/A\".\n",
        "    \"\"\"\n",
        "    cleaned = []\n",
        "    for text in text_list:\n",
        "        text = text.strip()  # Remove leading/trailing spaces\n",
        "        # Remove all occurrences of standalone numbers inside brackets: [2], [3], etc.\n",
        "        text = re.sub(r\"\\[\\s*\\d+\\s*\\]\", \"\", text)\n",
        "        # Remove unwanted keywords (CSS classes, special characters)\n",
        "        if text and not any(x in text for x in [\"mw-parser-output\", \"{\", \"}\",\"[\",\"]\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]):\n",
        "            cleaned.append(text)\n",
        "    return \", \".join(cleaned) if cleaned else \"N/A\"  # Return cleaned text or \"N/A\" if no text is left\n",
        "\n",
        "# Define the spider class that will crawl the Wikipedia page\n",
        "class WikiSpider(scrapy.Spider):\n",
        "    name = \"wiki_spider\"\n",
        "    start_urls = [\"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"]  # Start URL for the spider\n",
        "\n",
        "    def parse(self, response):\n",
        "        \"\"\"\n",
        "        Parse the main page and extract the data for each movie listed in the table.\n",
        "\n",
        "        Args:\n",
        "            response (scrapy.http.Response): The response object returned by Scrapy for the start URL.\n",
        "\n",
        "        Yields:\n",
        "            dict: A dictionary containing movie details including rank, title, box office, year, and a link to the movie page.\n",
        "        \"\"\"\n",
        "        table = response.xpath(\"(//table[contains(@class,'wikitable')])[1]\")  # Extract the first table with the class 'wikitable'\n",
        "        rows = table.xpath(\".//tr\")[1:]  # Skip the header row by selecting all rows except the first one\n",
        "\n",
        "        for row in rows:\n",
        "            # Extract rank, title, box office, and year from the row\n",
        "            rank = row.xpath(\"./td[1]/text()\").get()\n",
        "            title = row.xpath(\".//th/i/a/text() | .//th/span/i/a/text()\").get()\n",
        "            box_office = row.xpath(\".//td[3]/text()\").get()\n",
        "            box_office = re.sub(r\"[^\\d.]\", \"\", box_office)  # Clean up the box office value to retain only digits and decimal points\n",
        "            year = row.xpath(\".//td[4]/text()\").get()\n",
        "            relative_link = row.xpath(\"./th/i/a/@href | ./th/span/i/a/@href\").get()\n",
        "\n",
        "            if title and relative_link:\n",
        "                full_link = response.urljoin(relative_link)  # Create the full URL for the movie page\n",
        "\n",
        "                # Follow the link to the movie page and pass movie details to the next parsing method\n",
        "                yield response.follow(full_link, self.parse_movie, meta={\n",
        "                    'rank': rank.strip() if rank else \"N/A\",\n",
        "                    'title': title.strip(),\n",
        "                    'url': full_link,\n",
        "                    'box_office': box_office.strip() if box_office else \"N/A\",\n",
        "                    'year': year.strip() if year else \"N/A\"\n",
        "                })\n",
        "\n",
        "    def parse_movie(self, response):\n",
        "        \"\"\"\n",
        "        Parse individual movie pages to extract director and country information.\n",
        "\n",
        "        Args:\n",
        "            response (scrapy.http.Response): The response object returned by Scrapy for the movie page.\n",
        "\n",
        "        Yields:\n",
        "            dict: A dictionary containing detailed movie information including directors and country of origin.\n",
        "        \"\"\"\n",
        "        # Get movie details from the meta information passed in the previous method\n",
        "        rank = response.meta['rank']\n",
        "        title = response.meta['title']\n",
        "        url = response.meta['url']\n",
        "        box_office = response.meta['box_office']\n",
        "        year = response.meta['year']\n",
        "\n",
        "        # Extract director information from the movie page\n",
        "        directors = response.xpath(\"//table[contains(@class, 'infobox')]//th[contains(text(), 'Directed by')]/following-sibling::td//text()[normalize-space() and not(parent::sup)]\").getall()\n",
        "        directors = clean_text_list(directors)  # Clean the list of director names\n",
        "\n",
        "        # Extract country of origin from the movie page\n",
        "        country = response.xpath(\"//table[contains(@class, 'infobox')]//th[contains(text(), 'Country') or contains(text(), 'Countries')]/following-sibling::td//text()[normalize-space() and not(parent::sup)]\").getall()\n",
        "        country = clean_text_list(country)  # Clean the list of countries\n",
        "\n",
        "        # Yield the final data for each movie\n",
        "        yield {\n",
        "            \"Rank\": rank,\n",
        "            \"Title\": title,\n",
        "            \"Release Year\": year,\n",
        "            \"Directed by\": directors,\n",
        "            \"Box Office Revenue\": box_office,\n",
        "            \"Country of origin\": country\n",
        "        }\n",
        "\n",
        "# Set up the Scrapy process and specify where to save the results\n",
        "process = CrawlerProcess(settings={\n",
        "    \"FEEDS\": {\"output.json\": {\"format\": \"json\"}},  # Save output to a JSON file\n",
        "})\n",
        "\n",
        "# Start the crawling process\n",
        "process.crawl(WikiSpider)\n",
        "process.start()  # Run the spider to collect data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjvxeox0aviC",
        "outputId": "0e9cd218-f5ff-4e81-8fee-024844cd41fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: Twisted>=21.7.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.11.0)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.2.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.3.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.10.0)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (2.3.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (7.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.4.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (from scrapy) (5.1.3)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (5.3.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy) (1.17.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.11/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (25.1.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.1)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (24.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy) (75.1.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (2.32.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (3.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2025.1.31)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.11/dist-packages (2.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:scrapy.utils.log:Scrapy 2.12.0 started (bot: scrapybot)\n",
            "2025-02-26 16:56:28 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
            "INFO:scrapy.utils.log:Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2025-02-26 16:56:28 [scrapy.utils.log] INFO: Versions: lxml 5.3.1.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "INFO:scrapy.addons:Enabled addons:\n",
            "[]\n",
            "2025-02-26 16:56:28 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2025-02-26 16:56:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "INFO:scrapy.extensions.telnet:Telnet Password: d167f1a8d633e84c\n",
            "2025-02-26 16:56:28 [scrapy.extensions.telnet] INFO: Telnet Password: d167f1a8d633e84c\n",
            "INFO:scrapy.middleware:Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2025-02-26 16:56:28 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "INFO:scrapy.crawler:Overridden settings:\n",
            "{}\n",
            "2025-02-26 16:56:28 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2025-02-26 16:56:28 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "INFO:scrapy.middleware:Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2025-02-26 16:56:28 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "INFO:scrapy.middleware:Enabled item pipelines:\n",
            "[]\n",
            "2025-02-26 16:56:28 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "INFO:scrapy.core.engine:Spider opened\n",
            "2025-02-26 16:56:28 [scrapy.core.engine] INFO: Spider opened\n",
            "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2025-02-26 16:56:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n",
            "2025-02-26 16:56:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): publicsuffix.org:443\n",
            "2025-02-26 16:56:29 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443\n",
            "DEBUG:urllib3.connectionpool:https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 86820\n",
            "2025-02-26 16:56:29 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 86820\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/List_of_highest-grossing_films> (referer: None)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/List_of_highest-grossing_films> (referer: None)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar_(2009_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar_(2009_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Inside_Out_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Inside_Out_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Barbie_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Barbie_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Top_Gun:_Maverick> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Top_Gun:_Maverick> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Avengers_(2012_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Avengers_(2012_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Furious_7> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Furious_7> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Lion_King_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Lion_King_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Ne_Zha_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Ne_Zha_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Avatar_(2009_film)>\n",
            "{'Rank': '1', 'Title': 'Avatar', 'Release Year': '2009', 'Directed by': 'James Cameron', 'Box Office Revenue': '2923706026', 'Country of origin': 'United Kingdom, United States'}\n",
            "2025-02-26 16:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Avatar_(2009_film)>\n",
            "{'Rank': '1', 'Title': 'Avatar', 'Release Year': '2009', 'Directed by': 'James Cameron', 'Box Office Revenue': '2923706026', 'Country of origin': 'United Kingdom, United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_World>\n",
            "{'Rank': '10', 'Title': 'Jurassic World', 'Release Year': '2015', 'Directed by': 'Colin Trevorrow', 'Box Office Revenue': '1671537444', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_World>\n",
            "{'Rank': '10', 'Title': 'Jurassic World', 'Release Year': '2015', 'Directed by': 'Colin Trevorrow', 'Box Office Revenue': '1671537444', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Inside_Out_2>\n",
            "{'Rank': '9', 'Title': 'Inside Out 2', 'Release Year': '2024', 'Directed by': 'Kelsey Mann', 'Box Office Revenue': '1698863816', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Inside_Out_2>\n",
            "{'Rank': '9', 'Title': 'Inside Out 2', 'Release Year': '2024', 'Directed by': 'Kelsey Mann', 'Box Office Revenue': '1698863816', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Despicable_Me_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Despicable_Me_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Frozen_2>\n",
            "{'Rank': '15', 'Title': 'Frozen 2', 'Release Year': '2019', 'Directed by': 'Chris Buck, Jennifer Lee', 'Box Office Revenue': '1450026933', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Frozen_2>\n",
            "{'Rank': '15', 'Title': 'Frozen 2', 'Release Year': '2019', 'Directed by': 'Chris Buck, Jennifer Lee', 'Box Office Revenue': '1450026933', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Barbie_(film)>\n",
            "{'Rank': '16', 'Title': 'Barbie', 'Release Year': '2023', 'Directed by': 'Greta Gerwig', 'Box Office Revenue': '1447038421', 'Country of origin': 'United States, United Kingdom'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Barbie_(film)>\n",
            "{'Rank': '16', 'Title': 'Barbie', 'Release Year': '2023', 'Directed by': 'Greta Gerwig', 'Box Office Revenue': '1447038421', 'Country of origin': 'United States, United Kingdom'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Top_Gun:_Maverick>\n",
            "{'Rank': '14', 'Title': 'Top Gun: Maverick', 'Release Year': '2022', 'Directed by': 'Joseph Kosinski', 'Box Office Revenue': '1495696292', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Top_Gun:_Maverick>\n",
            "{'Rank': '14', 'Title': 'Top Gun: Maverick', 'Release Year': '2022', 'Directed by': 'Joseph Kosinski', 'Box Office Revenue': '1495696292', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron>\n",
            "{'Rank': '17', 'Title': 'Avengers: Age of Ultron', 'Release Year': '2015', 'Directed by': 'Joss Whedon', 'Box Office Revenue': '1402809540', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron>\n",
            "{'Rank': '17', 'Title': 'Avengers: Age of Ultron', 'Release Year': '2015', 'Directed by': 'Joss Whedon', 'Box Office Revenue': '1402809540', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Avengers_(2012_film)>\n",
            "{'Rank': '12', 'Title': 'The Avengers', 'Release Year': '2012', 'Directed by': 'Joss Whedon', 'Box Office Revenue': '1518815515', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Avengers_(2012_film)>\n",
            "{'Rank': '12', 'Title': 'The Avengers', 'Release Year': '2012', 'Directed by': 'Joss Whedon', 'Box Office Revenue': '1518815515', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Furious_7>\n",
            "{'Rank': '13', 'Title': 'Furious 7', 'Release Year': '2015', 'Directed by': 'James Wan', 'Box Office Revenue': '1515341399', 'Country of origin': 'United States, China'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Furious_7>\n",
            "{'Rank': '13', 'Title': 'Furious 7', 'Release Year': '2015', 'Directed by': 'James Wan', 'Box Office Revenue': '1515341399', 'Country of origin': 'United States, China'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Lion_King_(2019_film)>\n",
            "{'Rank': '11', 'Title': 'The Lion King', 'Release Year': '2019', 'Directed by': 'Jon Favreau', 'Box Office Revenue': '1656943394', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Lion_King_(2019_film)>\n",
            "{'Rank': '11', 'Title': 'The Lion King', 'Release Year': '2019', 'Directed by': 'Jon Favreau', 'Box Office Revenue': '1656943394', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Ne_Zha_2>\n",
            "{'Rank': '8', 'Title': 'Ne Zha 2', 'Release Year': '2025', 'Directed by': 'Jiaozi', 'Box Office Revenue': '1911164560', 'Country of origin': 'China'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Ne_Zha_2>\n",
            "{'Rank': '8', 'Title': 'Ne Zha 2', 'Release Year': '2025', 'Directed by': 'Jiaozi', 'Box Office Revenue': '1911164560', 'Country of origin': 'China'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Infinity_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Infinity_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Titanic_(1997_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Titanic_(1997_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_Park_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_Park_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Despicable_Me_3>\n",
            "{'Rank': '50', 'Title': 'Despicable Me 3', 'Release Year': '2017', 'Directed by': 'Pierre Coffin, Kyle Balda', 'Box Office Revenue': '1034800131', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Despicable_Me_3>\n",
            "{'Rank': '50', 'Title': 'Despicable Me 3', 'Release Year': '2017', 'Directed by': 'Pierre Coffin, Kyle Balda', 'Box Office Revenue': '1034800131', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home>\n",
            "{'Rank': '7', 'Title': 'Spider-Man: No Way Home', 'Release Year': '2021', 'Directed by': 'Jon Watts', 'Box Office Revenue': '1952732181', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home>\n",
            "{'Rank': '7', 'Title': 'Spider-Man: No Way Home', 'Release Year': '2021', 'Directed by': 'Jon Watts', 'Box Office Revenue': '1952732181', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides>\n",
            "{'Rank': '48', 'Title': 'Pirates of the Caribbean: On Stranger Tides', 'Release Year': '2011', 'Directed by': 'Rob Marshall', 'Box Office Revenue': '1045713802', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides>\n",
            "{'Rank': '48', 'Title': 'Pirates of the Caribbean: On Stranger Tides', 'Release Year': '2011', 'Directed by': 'Rob Marshall', 'Box Office Revenue': '1045713802', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Infinity_War>\n",
            "{'Rank': '6', 'Title': 'Avengers: Infinity War', 'Release Year': '2018', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '2048359754', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Infinity_War>\n",
            "{'Rank': '6', 'Title': 'Avengers: Infinity War', 'Release Year': '2018', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '2048359754', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens>\n",
            "{'Rank': '5', 'Title': 'Star Wars: The Force Awakens', 'Release Year': '2015', 'Directed by': 'J. J. Abrams', 'Box Office Revenue': '2068223624', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens>\n",
            "{'Rank': '5', 'Title': 'Star Wars: The Force Awakens', 'Release Year': '2015', 'Directed by': 'J. J. Abrams', 'Box Office Revenue': '2068223624', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Titanic_(1997_film)>\n",
            "{'Rank': '4', 'Title': 'Titanic', 'Release Year': '1997', 'Directed by': 'James Cameron', 'Box Office Revenue': '2257844554', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Titanic_(1997_film)>\n",
            "{'Rank': '4', 'Title': 'Titanic', 'Release Year': '1997', 'Directed by': 'James Cameron', 'Box Office Revenue': '2257844554', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water>\n",
            "{'Rank': '3', 'Title': 'Avatar: The Way of Water', 'Release Year': '2022', 'Directed by': 'James Cameron', 'Box Office Revenue': '2320250281', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water>\n",
            "{'Rank': '3', 'Title': 'Avatar: The Way of Water', 'Release Year': '2022', 'Directed by': 'James Cameron', 'Box Office Revenue': '2320250281', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_Park_(film)>\n",
            "{'Rank': '49', 'Title': 'Jurassic Park', 'Release Year': '1993', 'Directed by': 'Steven Spielberg', 'Box Office Revenue': '1037535230', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_Park_(film)>\n",
            "{'Rank': '49', 'Title': 'Jurassic Park', 'Release Year': '1993', 'Directed by': 'Steven Spielberg', 'Box Office Revenue': '1037535230', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace>\n",
            "{'Rank': '47', 'Title': 'Star Wars: Episode I – The Phantom Menace', 'Release Year': '1999', 'Directed by': 'George Lucas', 'Box Office Revenue': '1046515409', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace>\n",
            "{'Rank': '47', 'Title': 'Star Wars: Episode I – The Phantom Menace', 'Release Year': '1999', 'Directed by': 'George Lucas', 'Box Office Revenue': '1046515409', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Moana_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Moana_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_4> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_4> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Joker_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Joker_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Aladdin_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Aladdin_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Skyfall> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Skyfall> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Dark_Knight_Rises> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Dark_Knight_Rises> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Moana_2>\n",
            "{'Rank': '45', 'Title': 'Moana 2', 'Release Year': '2024', 'Directed by': 'David Derrick Jr., Jason Hand, Dana Ledoux Miller', 'Box Office Revenue': '1053422063', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Moana_2>\n",
            "{'Rank': '45', 'Title': 'Moana 2', 'Release Year': '2024', 'Directed by': 'David Derrick Jr., Jason Hand, Dana Ledoux Miller', 'Box Office Revenue': '1053422063', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Toy_Story_4>\n",
            "{'Rank': '41', 'Title': 'Toy Story 4', 'Release Year': '2019', 'Directed by': 'Josh Cooley', 'Box Office Revenue': '1073394593', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Toy_Story_4>\n",
            "{'Rank': '41', 'Title': 'Toy Story 4', 'Release Year': '2019', 'Directed by': 'Josh Cooley', 'Box Office Revenue': '1073394593', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Toy_Story_3>\n",
            "{'Rank': '42', 'Title': 'Toy Story 3', 'Release Year': '2010', 'Directed by': 'Lee Unkrich', 'Box Office Revenue': '1066970811', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Toy_Story_3>\n",
            "{'Rank': '42', 'Title': 'Toy Story 3', 'Release Year': '2010', 'Directed by': 'Lee Unkrich', 'Box Office Revenue': '1066970811', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Lord_of_the_Rings:_The_Return_of_the_King> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Lord_of_the_Rings:_The_Return_of_the_King> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest>\n",
            "{'Rank': '43', 'Title': \"Pirates of the Caribbean: Dead Man's Chest\", 'Release Year': '2006', 'Directed by': 'Gore Verbinski', 'Box Office Revenue': '1066179747', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest>\n",
            "{'Rank': '43', 'Title': \"Pirates of the Caribbean: Dead Man's Chest\", 'Release Year': '2006', 'Directed by': 'Gore Verbinski', 'Box Office Revenue': '1066179747', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_Marvel_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_Marvel_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Aquaman_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Aquaman_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Minions_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Minions_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Joker_(2019_film)>\n",
            "{'Rank': '39', 'Title': 'Joker', 'Release Year': '2019', 'Directed by': 'Todd Phillips', 'Box Office Revenue': '1074458282', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Joker_(2019_film)>\n",
            "{'Rank': '39', 'Title': 'Joker', 'Release Year': '2019', 'Directed by': 'Todd Phillips', 'Box Office Revenue': '1074458282', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Aladdin_(2019_film)>\n",
            "{'Rank': '46', 'Title': 'Aladdin', 'Release Year': '2019', 'Directed by': 'Guy Ritchie', 'Box Office Revenue': '1050693953', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Aladdin_(2019_film)>\n",
            "{'Rank': '46', 'Title': 'Aladdin', 'Release Year': '2019', 'Directed by': 'Guy Ritchie', 'Box Office Revenue': '1050693953', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker>\n",
            "{'Rank': '40', 'Title': 'Star Wars: The Rise of Skywalker', 'Release Year': '2019', 'Directed by': 'J. J. Abrams', 'Box Office Revenue': '1074144248', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker>\n",
            "{'Rank': '40', 'Title': 'Star Wars: The Rise of Skywalker', 'Release Year': '2019', 'Directed by': 'J. J. Abrams', 'Box Office Revenue': '1074144248', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction>\n",
            "{'Rank': '37', 'Title': 'Transformers: Age of Extinction', 'Release Year': '2014', 'Directed by': 'Michael Bay', 'Box Office Revenue': '1104054072', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction>\n",
            "{'Rank': '37', 'Title': 'Transformers: Age of Extinction', 'Release Year': '2014', 'Directed by': 'Michael Bay', 'Box Office Revenue': '1104054072', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Skyfall>\n",
            "{'Rank': '36', 'Title': 'Skyfall', 'Release Year': '2012', 'Directed by': 'Sam Mendes', 'Box Office Revenue': '1108594137', 'Country of origin': 'United Kingdom, United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Skyfall>\n",
            "{'Rank': '36', 'Title': 'Skyfall', 'Release Year': '2012', 'Directed by': 'Sam Mendes', 'Box Office Revenue': '1108594137', 'Country of origin': 'United Kingdom, United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon>\n",
            "{'Rank': '35', 'Title': 'Transformers: Dark of the Moon', 'Release Year': '2011', 'Directed by': 'Michael Bay', 'Box Office Revenue': '1123794079', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon>\n",
            "{'Rank': '35', 'Title': 'Transformers: Dark of the Moon', 'Release Year': '2011', 'Directed by': 'Michael Bay', 'Box Office Revenue': '1123794079', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Dark_Knight_Rises>\n",
            "{'Rank': '38', 'Title': 'The Dark Knight Rises', 'Release Year': '2012', 'Directed by': 'Christopher Nolan', 'Box Office Revenue': '1081169825', 'Country of origin': 'United States, United Kingdom'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Dark_Knight_Rises>\n",
            "{'Rank': '38', 'Title': 'The Dark Knight Rises', 'Release Year': '2012', 'Directed by': 'Christopher Nolan', 'Box Office Revenue': '1081169825', 'Country of origin': 'United States, United Kingdom'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_America:_Civil_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_America:_Civil_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Lord_of_the_Rings:_The_Return_of_the_King>\n",
            "{'Rank': '32', 'Title': 'The Lord of the Rings: The Return of the King', 'Release Year': '2003', 'Directed by': 'Peter Jackson', 'Box Office Revenue': '1147997407', 'Country of origin': 'New Zealand, Germany, United States'}\n",
            "2025-02-26 16:56:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Lord_of_the_Rings:_The_Return_of_the_King>\n",
            "{'Rank': '32', 'Title': 'The Lord of the Rings: The Return of the King', 'Release Year': '2003', 'Directed by': 'Peter Jackson', 'Box Office Revenue': '1147997407', 'Country of origin': 'New Zealand, Germany, United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Iron_Man_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Iron_Man_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Fate_of_the_Furious> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Fate_of_the_Furious> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Incredibles_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Incredibles_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home>\n",
            "{'Rank': '33', 'Title': 'Spider-Man: Far From Home', 'Release Year': '2019', 'Directed by': 'Jon Watts', 'Box Office Revenue': '1132679685', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home>\n",
            "{'Rank': '33', 'Title': 'Spider-Man: Far From Home', 'Release Year': '2019', 'Directed by': 'Jon Watts', 'Box Office Revenue': '1132679685', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Captain_Marvel_(film)>\n",
            "{'Rank': '34', 'Title': 'Captain Marvel', 'Release Year': '2019', 'Directed by': 'Anna Boden, Ryan Fleck', 'Box Office Revenue': '1128274794', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Captain_Marvel_(film)>\n",
            "{'Rank': '34', 'Title': 'Captain Marvel', 'Release Year': '2019', 'Directed by': 'Anna Boden, Ryan Fleck', 'Box Office Revenue': '1128274794', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Aquaman_(film)>\n",
            "{'Rank': '31', 'Title': 'Aquaman', 'Release Year': '2018', 'Directed by': 'James Wan', 'Box Office Revenue': '1148528393', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Aquaman_(film)>\n",
            "{'Rank': '31', 'Title': 'Aquaman', 'Release Year': '2018', 'Directed by': 'James Wan', 'Box Office Revenue': '1148528393', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Minions_(film)>\n",
            "{'Rank': '29', 'Title': 'Minions', 'Release Year': '2015', 'Directed by': 'Pierre Coffin, Kyle Balda', 'Box Office Revenue': '1159444662', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Minions_(film)>\n",
            "{'Rank': '29', 'Title': 'Minions', 'Release Year': '2015', 'Directed by': 'Pierre Coffin, Kyle Balda', 'Box Office Revenue': '1159444662', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story>\n",
            "{'Rank': '44', 'Title': 'Rogue One: A Star Wars Story', 'Release Year': '2016', 'Directed by': 'Gareth Edwards', 'Box Office Revenue': '1057420387', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story>\n",
            "{'Rank': '44', 'Title': 'Rogue One: A Star Wars Story', 'Release Year': '2016', 'Directed by': 'Gareth Edwards', 'Box Office Revenue': '1057420387', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Captain_America:_Civil_War>\n",
            "{'Rank': '30', 'Title': 'Captain America: Civil War', 'Release Year': '2016', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '1153337496', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Captain_America:_Civil_War>\n",
            "{'Rank': '30', 'Title': 'Captain America: Civil War', 'Release Year': '2016', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '1153337496', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_(2013_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_(2013_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Iron_Man_3>\n",
            "{'Rank': '28', 'Title': 'Iron Man 3', 'Release Year': '2013', 'Directed by': 'Shane Black', 'Box Office Revenue': '1214811252', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Iron_Man_3>\n",
            "{'Rank': '28', 'Title': 'Iron Man 3', 'Release Year': '2013', 'Directed by': 'Shane Black', 'Box Office Revenue': '1214811252', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Fate_of_the_Furious>\n",
            "{'Rank': '27', 'Title': 'The Fate of the Furious', 'Release Year': '2017', 'Directed by': 'F. Gary Gray', 'Box Office Revenue': '1238764765', 'Country of origin': 'United States, China'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Fate_of_the_Furious>\n",
            "{'Rank': '27', 'Title': 'The Fate of the Furious', 'Release Year': '2017', 'Directed by': 'F. Gary Gray', 'Box Office Revenue': '1238764765', 'Country of origin': 'United States, China'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Incredibles_2>\n",
            "{'Rank': '26', 'Title': 'Incredibles 2', 'Release Year': '2018', 'Directed by': 'Brad Bird', 'Box Office Revenue': '1242805359', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Incredibles_2>\n",
            "{'Rank': '26', 'Title': 'Incredibles 2', 'Release Year': '2018', 'Directed by': 'Brad Bird', 'Box Office Revenue': '1242805359', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Black_Panther_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Black_Panther_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)>\n",
            "{'Rank': '25', 'Title': 'Beauty and the Beast', 'Release Year': '2017', 'Directed by': 'Bill Condon', 'Box Office Revenue': '1263521126', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)>\n",
            "{'Rank': '25', 'Title': 'Beauty and the Beast', 'Release Year': '2017', 'Directed by': 'Bill Condon', 'Box Office Revenue': '1263521126', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Frozen_(2013_film)>\n",
            "{'Rank': '24', 'Title': 'Frozen', 'Release Year': '2013', 'Directed by': 'Chris Buck, Jennifer Lee', 'Box Office Revenue': '1290000000', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Frozen_(2013_film)>\n",
            "{'Rank': '24', 'Title': 'Frozen', 'Release Year': '2013', 'Directed by': 'Chris Buck, Jennifer Lee', 'Box Office Revenue': '1290000000', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2>\n",
            "{'Rank': '20', 'Title': 'Harry Potter and the Deathly Hallows – Part 2', 'Release Year': '2011', 'Directed by': 'David Yates', 'Box Office Revenue': '1342139727', 'Country of origin': 'United Kingdom, United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2>\n",
            "{'Rank': '20', 'Title': 'Harry Potter and the Deathly Hallows – Part 2', 'Release Year': '2011', 'Directed by': 'David Yates', 'Box Office Revenue': '1342139727', 'Country of origin': 'United Kingdom, United States'}\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Endgame> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "2025-02-26 16:56:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Endgame> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie>\n",
            "{'Rank': '18', 'Title': 'The Super Mario Bros. Movie', 'Release Year': '2023', 'Directed by': 'Aaron Horvath, Michael Jelenic', 'Box Office Revenue': '1362566989', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie>\n",
            "{'Rank': '18', 'Title': 'The Super Mario Bros. Movie', 'Release Year': '2023', 'Directed by': 'Aaron Horvath, Michael Jelenic', 'Box Office Revenue': '1362566989', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom>\n",
            "{'Rank': '23', 'Title': 'Jurassic World: Fallen Kingdom', 'Release Year': '2018', 'Directed by': 'J. A. Bayona', 'Box Office Revenue': '1308473425', 'Country of origin': 'China, United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom>\n",
            "{'Rank': '23', 'Title': 'Jurassic World: Fallen Kingdom', 'Release Year': '2018', 'Directed by': 'J. A. Bayona', 'Box Office Revenue': '1308473425', 'Country of origin': 'China, United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi>\n",
            "{'Rank': '22', 'Title': 'Star Wars: The Last Jedi', 'Release Year': '2017', 'Directed by': 'Rian Johnson', 'Box Office Revenue': '1332539889', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi>\n",
            "{'Rank': '22', 'Title': 'Star Wars: The Last Jedi', 'Release Year': '2017', 'Directed by': 'Rian Johnson', 'Box Office Revenue': '1332539889', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Black_Panther_(film)>\n",
            "{'Rank': '19', 'Title': 'Black Panther', 'Release Year': '2018', 'Directed by': 'Ryan Coogler', 'Box Office Revenue': '1347280838', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Black_Panther_(film)>\n",
            "{'Rank': '19', 'Title': 'Black Panther', 'Release Year': '2018', 'Directed by': 'Ryan Coogler', 'Box Office Revenue': '1347280838', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine>\n",
            "{'Rank': '21', 'Title': 'Deadpool & Wolverine', 'Release Year': '2024', 'Directed by': 'Shawn Levy', 'Box Office Revenue': '1338073645', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine>\n",
            "{'Rank': '21', 'Title': 'Deadpool & Wolverine', 'Release Year': '2024', 'Directed by': 'Shawn Levy', 'Box Office Revenue': '1338073645', 'Country of origin': 'United States'}\n",
            "DEBUG:scrapy.core.scraper:Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Endgame>\n",
            "{'Rank': '2', 'Title': 'Avengers: Endgame', 'Release Year': '2019', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '2797501328', 'Country of origin': 'United States'}\n",
            "2025-02-26 16:56:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://en.wikipedia.org/wiki/Avengers:_Endgame>\n",
            "{'Rank': '2', 'Title': 'Avengers: Endgame', 'Release Year': '2019', 'Directed by': 'Anthony Russo, Joe Russo', 'Box Office Revenue': '2797501328', 'Country of origin': 'United States'}\n",
            "INFO:scrapy.core.engine:Closing spider (finished)\n",
            "2025-02-26 16:56:33 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "INFO:scrapy.extensions.feedexport:Stored json feed (50 items) in: output.json\n",
            "2025-02-26 16:56:33 [scrapy.extensions.feedexport] INFO: Stored json feed (50 items) in: output.json\n",
            "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 24154,\n",
            " 'downloader/request_count': 51,\n",
            " 'downloader/request_method_count/GET': 51,\n",
            " 'downloader/response_bytes': 6087063,\n",
            " 'downloader/response_count': 51,\n",
            " 'downloader/response_status_count/200': 51,\n",
            " 'elapsed_time_seconds': 4.520631,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2025, 2, 26, 16, 56, 33, 397851, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 35835252,\n",
            " 'httpcompression/response_count': 51,\n",
            " 'item_scraped_count': 50,\n",
            " 'items_per_minute': None,\n",
            " 'log_count/DEBUG': 104,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 150773760,\n",
            " 'memusage/startup': 150773760,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 51,\n",
            " 'responses_per_minute': None,\n",
            " 'scheduler/dequeued': 51,\n",
            " 'scheduler/dequeued/memory': 51,\n",
            " 'scheduler/enqueued': 51,\n",
            " 'scheduler/enqueued/memory': 51,\n",
            " 'start_time': datetime.datetime(2025, 2, 26, 16, 56, 28, 877220, tzinfo=datetime.timezone.utc)}\n",
            "2025-02-26 16:56:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 24154,\n",
            " 'downloader/request_count': 51,\n",
            " 'downloader/request_method_count/GET': 51,\n",
            " 'downloader/response_bytes': 6087063,\n",
            " 'downloader/response_count': 51,\n",
            " 'downloader/response_status_count/200': 51,\n",
            " 'elapsed_time_seconds': 4.520631,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2025, 2, 26, 16, 56, 33, 397851, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 35835252,\n",
            " 'httpcompression/response_count': 51,\n",
            " 'item_scraped_count': 50,\n",
            " 'items_per_minute': None,\n",
            " 'log_count/DEBUG': 104,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 150773760,\n",
            " 'memusage/startup': 150773760,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 51,\n",
            " 'responses_per_minute': None,\n",
            " 'scheduler/dequeued': 51,\n",
            " 'scheduler/dequeued/memory': 51,\n",
            " 'scheduler/enqueued': 51,\n",
            " 'scheduler/enqueued/memory': 51,\n",
            " 'start_time': datetime.datetime(2025, 2, 26, 16, 56, 28, 877220, tzinfo=datetime.timezone.utc)}\n",
            "INFO:scrapy.core.engine:Spider closed (finished)\n",
            "2025-02-26 16:56:33 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have our cleaned data in output.json. The next step is parse our data from json to database. I have chosen SQLite, since our data is small and we won't use database anyway😀"
      ],
      "metadata": {
        "id": "wveK9txVKcI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "with open(\"output.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "    films_data = json.load(file)"
      ],
      "metadata": {
        "id": "uufu6yrVvzG5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(\"films.db\")\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "qJOTl1X2i2Rk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS films (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    title TEXT NOT NULL,\n",
        "    release_year INTEGER,\n",
        "    director TEXT,\n",
        "    box_office REAL,\n",
        "    country TEXT\n",
        ")\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRaFPvdV0KVt",
        "outputId": "8dd1cd1c-7cda-4943-dea4-5c64ed61f5b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7cb4e6720840>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created our database and table films. So the next piece of code is for adding entities into our table"
      ],
      "metadata": {
        "id": "X0bEd0MBLHkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for film in films_data:\n",
        "    cursor.execute(\"\"\"\n",
        "    INSERT INTO films (title, release_year, director, box_office, country)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        film.get(\"Title\"),\n",
        "        film.get(\"Release Year\"),\n",
        "        film.get(\"Directed by\"),\n",
        "        float(film.get(\"Box Office Revenue\", 0)),  # Convert box office to float\n",
        "        film.get(\"Country of origin\")\n",
        "    ))\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "g5UHLlM50W0y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is done, now we can use our database, but unfortunately we need to transform our database to json file again"
      ],
      "metadata": {
        "id": "a9liMWUSLWfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(\"films.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch all data from the films table\n",
        "cursor.execute(\"SELECT * FROM films\")\n",
        "films = cursor.fetchall()\n",
        "\n",
        "# Get column names\n",
        "columns = [description[0] for description in cursor.description]\n",
        "\n",
        "# Convert data to JSON format\n",
        "films_list = [dict(zip(columns, film)) for film in films]\n",
        "\n",
        "# Save to a JSON file\n",
        "json_file_path = \"films_data.json\"\n",
        "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(films_list, json_file, indent=4)\n",
        "\n",
        "print(f\"Data exported to {json_file_path}\")\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS4_Xqhb5v3s",
        "outputId": "af47b7a8-857d-4660-e565-23b60428e49a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to films_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are finnaly done. The next part is to use this data in our web page on github."
      ],
      "metadata": {
        "id": "P7nqjbTZLmI5"
      }
    }
  ]
}